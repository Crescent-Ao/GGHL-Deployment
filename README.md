# GGHL-Deployment
初步计划实现对以下平台的推理，分别是
- NCNN
- openvino
- tensorrt
- onnxruntime
## TensorRT
FP-16 load image 16.32ms
FP-16 nms 48.32ms
FP-16 inference 5ms
